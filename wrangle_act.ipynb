{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nadav\\\\Documents\\\\dog_data_wrangling\\\\venv\\\\Scripts\\\\python.exe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gather # gathering functions module, shift+tab on each function call bellow for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ~Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gather.download_file_from_url(url_path='link.txt', destination='image_predictions.tsv')` **\\*file already exists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function download_file_from_url in module gather:\n",
      "\n",
      "download_file_from_url(url_path, destination)\n",
      "    Save File From a given url.\n",
      "    \n",
      "    :param url_path: (str) a path a file containing the url.\n",
      "    :param destination: (str) a path to save the response at.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gather.download_file_from_url) # doc for the above function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auth object:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = gather.get_auth(auth_file='auth.txt') # get authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Archive data DataFrame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   tweet_id                    2356 non-null   object \n",
      " 1   in_reply_to_status_id       78 non-null     float64\n",
      " 2   in_reply_to_user_id         78 non-null     float64\n",
      " 3   timestamp                   2356 non-null   object \n",
      " 4   source                      2356 non-null   object \n",
      " 5   text                        2356 non-null   object \n",
      " 6   retweeted_status_id         181 non-null    float64\n",
      " 7   retweeted_status_user_id    181 non-null    float64\n",
      " 8   retweeted_status_timestamp  181 non-null    object \n",
      " 9   expanded_urls               2297 non-null   object \n",
      " 10  rating_numerator            2356 non-null   int64  \n",
      " 11  rating_denominator          2356 non-null   int64  \n",
      " 12  name                        2356 non-null   object \n",
      " 13  doggo                       2356 non-null   object \n",
      " 14  floofer                     2356 non-null   object \n",
      " 15  pupper                      2356 non-null   object \n",
      " 16  puppo                       2356 non-null   object \n",
      "dtypes: float64(4), int64(2), object(11)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "archive_original = pd.read_csv('twitter-archive-enhanced.csv', \n",
    "                               dtype={'tweet_id': str})\n",
    "dump_lst = archive_original['tweet_id'] # to get list of id's as strings\n",
    "archive_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***notice-loaded to json instead, relevant attributes only (rt and favorite counts):***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gather.dump_tweets_data(id_lst=dump_lst, auth=auth)` **\\*takes about 30 min, file already exists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dump_tweets_data in module gather:\n",
      "\n",
      "dump_tweets_data(id_lst, auth)\n",
      "    Dump tweets' id, retweet count and favorite count into json file.\n",
      "    \n",
      "    :param id_lst: (list[str]) a list containing tweet id's.\n",
      "    :param auth: (tweepy.auth.OAuth1UserHandler) an auth object.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gather.dump_tweets_data) # doc for the above function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tweets' counts DataFrame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              2356 non-null   object \n",
      " 1   favorite_count  2326 non-null   float64\n",
      " 2   retweet_count   2326 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 55.3+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_cnts = pd.read_json('tweets_data.json', dtype={'id': str})\n",
    "tweet_cnts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**image predictions DataFrame:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   tweet_id  2075 non-null   object \n",
      " 1   jpg_url   2075 non-null   object \n",
      " 2   img_num   2075 non-null   int64  \n",
      " 3   p1        2075 non-null   object \n",
      " 4   p1_conf   2075 non-null   float64\n",
      " 5   p1_dog    2075 non-null   bool   \n",
      " 6   p2        2075 non-null   object \n",
      " 7   p2_conf   2075 non-null   float64\n",
      " 8   p2_dog    2075 non-null   bool   \n",
      " 9   p3        2075 non-null   object \n",
      " 10  p3_conf   2075 non-null   float64\n",
      " 11  p3_dog    2075 non-null   bool   \n",
      "dtypes: bool(3), float64(3), int64(1), object(5)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "img_preds = pd.read_csv('image_predictions.tsv', sep='\\t', \n",
    "                        dtype={'tweet_id': str})\n",
    "img_preds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                                                     878404777348136964\n",
       "in_reply_to_status_id                                                       NaN\n",
       "in_reply_to_user_id                                                         NaN\n",
       "timestamp                                             2017-06-24 00:09:53 +0000\n",
       "source                        <a href=\"http://twitter.com/download/iphone\" r...\n",
       "text                          RT @dog_rates: Meet Shadow. In an attempt to r...\n",
       "retweeted_status_id                                        878281511006478336.0\n",
       "retweeted_status_user_id                                           4196983835.0\n",
       "retweeted_status_timestamp                            2017-06-23 16:00:04 +0000\n",
       "expanded_urls                 https://www.gofundme.com/3yd6y1c,https://twitt...\n",
       "rating_numerator                                                             13\n",
       "rating_denominator                                                           10\n",
       "name                                                                     Shadow\n",
       "doggo                                                                      None\n",
       "floofer                                                                    None\n",
       "pupper                                                                     None\n",
       "puppo                                                                      None\n",
       "Name: 73, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive_original.loc[73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "3.\n",
    "\n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n",
    "\n",
    "7.\n",
    "\n",
    "8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`archive_original` issues:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inappropriate data type for column `in_reply_to_status_id`,                   \n",
    "`in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, float -> str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1.\n",
    "\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
